{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Value Customer Identification (Insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler,MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, pickle, s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip list --format=freeze > requirements_production.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_key_id = os.environ.get( \"AWS_ACCESS_KEY_ID\" )\n",
    "aws_key_secret = os.environ.get( \"AWS_SECRET_ACCESS_KEY\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = pd.read_csv(\"../../cred.csv\", encoding='latin1')\n",
    "aws_key_id = cred[\"Access key ID\"][0]\n",
    "aws_key_secret = cred[\"Secret access key\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\s3fs\\core.py:110\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[1;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    111\u001b[0m \u001b[39mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\aiobotocore\\client.py:358\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    357\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    359\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (403) when calling the HeadObject operation: Forbidden",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\cluster_deploy.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39ms3://insiders-clustering-deploy/data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49m{ \u001b[39m\"\u001b[39;49m\u001b[39mkey\u001b[39;49m\u001b[39m\"\u001b[39;49m:aws_key_id,\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                                                  \u001b[39m\"\u001b[39;49m\u001b[39msecret\u001b[39;49m\u001b[39m\"\u001b[39;49m:aws_key_secret}, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatin1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#df0 = pd.read_parquet('data.parquet')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#df0 = pd.read_csv('data.csv')                                                                                                \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df0\u001b[39m.\u001b[39mcolumns\u001b[39m=\u001b[39mdf0\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\io\\common.py:670\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    667\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    669\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 670\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    671\u001b[0m     path_or_buf,\n\u001b[0;32m    672\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    673\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    674\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    675\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    676\u001b[0m )\n\u001b[0;32m    678\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    679\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\pandas\\io\\common.py:398\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    394\u001b[0m             storage_options \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(storage_options)\n\u001b[0;32m    395\u001b[0m             storage_options[\u001b[39m\"\u001b[39m\u001b[39manon\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    396\u001b[0m         file_obj \u001b[39m=\u001b[39m fsspec\u001b[39m.\u001b[39;49mopen(\n\u001b[0;32m    397\u001b[0m             filepath_or_buffer, mode\u001b[39m=\u001b[39;49mfsspec_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(storage_options \u001b[39mor\u001b[39;49;00m {})\n\u001b[1;32m--> 398\u001b[0m         )\u001b[39m.\u001b[39;49mopen()\n\u001b[0;32m    400\u001b[0m     \u001b[39mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    401\u001b[0m         filepath_or_buffer\u001b[39m=\u001b[39mfile_obj,\n\u001b[0;32m    402\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    405\u001b[0m         mode\u001b[39m=\u001b[39mfsspec_mode,\n\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m \u001b[39melif\u001b[39;00m storage_options:\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\core.py:135\u001b[0m, in \u001b[0;36mOpenFile.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    129\u001b[0m     \u001b[39m\"\"\"Materialise this as a real open file without context\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[39m    The OpenFile object should be explicitly closed to avoid enclosed file\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m    instances persisting. You must, therefore, keep a reference to the OpenFile\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    during the life of the file-like it generates.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__enter__\u001b[39;49m()\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\core.py:103\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    101\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 103\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[0;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfobjects \u001b[39m=\u001b[39m [f]\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\spec.py:1034\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1033\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[1;32m-> 1034\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open(\n\u001b[0;32m   1035\u001b[0m         path,\n\u001b[0;32m   1036\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   1037\u001b[0m         block_size\u001b[39m=\u001b[39mblock_size,\n\u001b[0;32m   1038\u001b[0m         autocommit\u001b[39m=\u001b[39mac,\n\u001b[0;32m   1039\u001b[0m         cache_options\u001b[39m=\u001b[39mcache_options,\n\u001b[0;32m   1040\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1041\u001b[0m     )\n\u001b[0;32m   1042\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\s3fs\\core.py:605\u001b[0m, in \u001b[0;36mS3FileSystem._open\u001b[1;34m(self, path, mode, block_size, acl, version_id, fill_cache, cache_type, autocommit, requester_pays, cache_options, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[39mif\u001b[39;00m cache_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m     cache_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_cache_type\n\u001b[1;32m--> 605\u001b[0m \u001b[39mreturn\u001b[39;00m S3File(\n\u001b[0;32m    606\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    607\u001b[0m     path,\n\u001b[0;32m    608\u001b[0m     mode,\n\u001b[0;32m    609\u001b[0m     block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[0;32m    610\u001b[0m     acl\u001b[39m=\u001b[39;49macl,\n\u001b[0;32m    611\u001b[0m     version_id\u001b[39m=\u001b[39;49mversion_id,\n\u001b[0;32m    612\u001b[0m     fill_cache\u001b[39m=\u001b[39;49mfill_cache,\n\u001b[0;32m    613\u001b[0m     s3_additional_kwargs\u001b[39m=\u001b[39;49mkw,\n\u001b[0;32m    614\u001b[0m     cache_type\u001b[39m=\u001b[39;49mcache_type,\n\u001b[0;32m    615\u001b[0m     autocommit\u001b[39m=\u001b[39;49mautocommit,\n\u001b[0;32m    616\u001b[0m     requester_pays\u001b[39m=\u001b[39;49mrequester_pays,\n\u001b[0;32m    617\u001b[0m     cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[0;32m    618\u001b[0m )\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\s3fs\\core.py:1919\u001b[0m, in \u001b[0;36mS3File.__init__\u001b[1;34m(self, s3, path, mode, block_size, acl, version_id, fill_cache, s3_additional_kwargs, autocommit, cache_type, requester_pays, cache_options)\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetails \u001b[39m=\u001b[39m s3\u001b[39m.\u001b[39minfo(path)\n\u001b[0;32m   1918\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetails\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mVersionId\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1919\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m   1920\u001b[0m     s3,\n\u001b[0;32m   1921\u001b[0m     path,\n\u001b[0;32m   1922\u001b[0m     mode,\n\u001b[0;32m   1923\u001b[0m     block_size,\n\u001b[0;32m   1924\u001b[0m     autocommit\u001b[39m=\u001b[39;49mautocommit,\n\u001b[0;32m   1925\u001b[0m     cache_type\u001b[39m=\u001b[39;49mcache_type,\n\u001b[0;32m   1926\u001b[0m     cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[0;32m   1927\u001b[0m )\n\u001b[0;32m   1928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs  \u001b[39m# compatibility\u001b[39;00m\n\u001b[0;32m   1930\u001b[0m \u001b[39m# when not using autocommit we want to have transactional state to manage\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\spec.py:1382\u001b[0m, in \u001b[0;36mAbstractBufferedFile.__init__\u001b[1;34m(self, fs, path, mode, block_size, autocommit, cache_type, cache_options, size, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m size\n\u001b[0;32m   1381\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1382\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetails[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m caches[cache_type](\n\u001b[0;32m   1384\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch_range, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcache_options\n\u001b[0;32m   1385\u001b[0m     )\n\u001b[0;32m   1386\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\spec.py:1395\u001b[0m, in \u001b[0;36mAbstractBufferedFile.details\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   1393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetails\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49minfo(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath)\n\u001b[0;32m   1396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\asyn.py:111\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    110\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m obj \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloop, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\asyn.py:96\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m FSTimeoutError \u001b[39mfrom\u001b[39;00m \u001b[39mreturn_result\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(return_result, \u001b[39mBaseException\u001b[39;00m):\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mraise\u001b[39;00m return_result\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m return_result\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\fsspec\\asyn.py:53\u001b[0m, in \u001b[0;36m_runner\u001b[1;34m(event, coro, result, timeout)\u001b[0m\n\u001b[0;32m     51\u001b[0m     coro \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mwait_for(coro, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m coro\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m     55\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m ex\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\s3fs\\core.py:1140\u001b[0m, in \u001b[0;36mS3FileSystem._info\u001b[1;34m(self, path, bucket, key, refresh, version_id)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m key:\n\u001b[0;32m   1139\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_s3(\n\u001b[0;32m   1141\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhead_object\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1142\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs,\n\u001b[0;32m   1143\u001b[0m             Bucket\u001b[39m=\u001b[39mbucket,\n\u001b[0;32m   1144\u001b[0m             Key\u001b[39m=\u001b[39mkey,\n\u001b[0;32m   1145\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mversion_id_kw(version_id),\n\u001b[0;32m   1146\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreq_kw,\n\u001b[0;32m   1147\u001b[0m         )\n\u001b[0;32m   1148\u001b[0m         \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m   1149\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m: out\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1150\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLastModified\u001b[39m\u001b[39m\"\u001b[39m: out[\u001b[39m\"\u001b[39m\u001b[39mLastModified\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mContentType\u001b[39m\u001b[39m\"\u001b[39m: out\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContentType\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1157\u001b[0m         }\n\u001b[0;32m   1158\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\s3fs\\core.py:332\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[1;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCALL: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, akwarglist, kw2)\n\u001b[0;32m    331\u001b[0m additional_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_s3_method_kwargs(method, \u001b[39m*\u001b[39makwarglist, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 332\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m _error_wrapper(\n\u001b[0;32m    333\u001b[0m     method, kwargs\u001b[39m=\u001b[39madditional_kwargs, retries\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretries\n\u001b[0;32m    334\u001b[0m )\n",
      "File \u001b[1;32mp:\\Anaconda3\\envs\\automl\\lib\\site-packages\\s3fs\\core.py:137\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[1;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[0;32m    135\u001b[0m         err \u001b[39m=\u001b[39m e\n\u001b[0;32m    136\u001b[0m err \u001b[39m=\u001b[39m translate_boto_error(err)\n\u001b[1;32m--> 137\u001b[0m \u001b[39mraise\u001b[39;00m err\n",
      "\u001b[1;31mPermissionError\u001b[0m: Forbidden"
     ]
    }
   ],
   "source": [
    "df0 = pd.read_csv('s3://insiders-clustering-deploy/data.csv', storage_options={ \"key\":aws_key_id,\n",
    "                                                                                 \"secret\":aws_key_secret}, encoding='latin1')\n",
    "#df0 = pd.read_parquet('data.parquet')\n",
    "#df0 = pd.read_csv('data.csv')                                                                                                \n",
    "df0.columns=df0.columns.str.lower()\n",
    "df0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing=df1[df1['customerid'].isna()]\n",
    "df_not_missing=df1[~df1['customerid'].isna()]\n",
    "df_missing[df_missing['invoiceno'].isin(df_not_missing['invoiceno'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reference\n",
    "df_backup = pd.DataFrame( df_missing['invoiceno'].drop_duplicates())\n",
    "df_backup['customerid']=np.arange(80000, 80000+len( df_backup ), 1)\n",
    "\n",
    "# merge original with reference datafarme\n",
    "df1 = df1.merge(df_backup, on='invoiceno', how='left')\n",
    "\n",
    "#coalesce\n",
    "df1['customerid']=df1['customerid_x'].combine_first( df1['customerid_y'])\n",
    "\n",
    "#drop extra columns\n",
    "df1 = df1.drop( columns=['customerid_x','customerid_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 data types treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['invoicedate']=df1['invoicedate'].str.split(expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['invoicedate'] = pd.to_datetime( df1['invoicedate'], format=\"%m/%d/%Y\",errors='coerce')\n",
    "df1['customerid'] = df1['customerid'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Feature Filtering/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532618, 8)\n"
     ]
    }
   ],
   "source": [
    " # ----------------------  Numerical attributes ----------------\n",
    " # purhcases df and returns df\n",
    "returns = df2.loc[df2['quantity'] < 0, :]\n",
    "purchases = df2.loc[df2['quantity'] >= 0, :]\n",
    "\n",
    "\n",
    "#drop invoices with only letters\n",
    "df2=df2[~df2['invoiceno'].str.contains('[^0-9]+', na=False)]\n",
    "\n",
    "#filter only stockcodes with numbers\n",
    "#df2=df2[df2['stockcode'].str.contains('[0-9]+', na=False)]\n",
    "print(df2.shape)\n",
    "\n",
    "\n",
    "# ------------------ Categorical attributes -------------------\n",
    "# drop description\n",
    "df2 = df2.drop( columns='description', axis=1 )\n",
    "\n",
    "# drop \"unspecifiec\" and \"european communoty\" countries -  \n",
    "df2 = df2[~df2['country'].isin( [\"European Community\",'Unspecified' ] ) ]\n",
    "\n",
    "\n",
    "# --------------------- Filter bad customer ----------------- (Section 5 Exploratory Data Analysis)\n",
    "df2=df2[df2['customerid']!=16446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref=df2[['customerid']].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 profit (gross revenue - gross outgoings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gross revenue\n",
    "purchases['gross_revenue'] = purchases['quantity'] * purchases['unitprice']\n",
    "df_monetary = purchases[['customerid', 'gross_revenue']].groupby( 'customerid').sum().reset_index()\n",
    "df_ref=df_ref.merge(df_monetary,on='customerid',how='left').fillna(0)\n",
    "\n",
    "\n",
    "# gross outgoings\n",
    "returns['gross_returns'] = returns['quantity'] * returns['unitprice']*-1\n",
    "df_returns = returns[['customerid', 'gross_returns']].groupby( 'customerid').sum().reset_index()\n",
    "df_ref=df_ref.merge(df_returns,on='customerid',how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recency\n",
    "df_recency = purchases.groupby( 'customerid').max().reset_index()\n",
    "df_recency['recencydays'] = ( purchases['invoicedate'].max() - df_recency['invoicedate'] ).dt.days\n",
    "df_recency= df_recency[['customerid','recencydays']].copy()\n",
    "df_ref=df_ref.merge(df_recency, how='left', on='customerid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 quantity of items kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity of products purchased\n",
    "df_freq = purchases[['customerid', 'quantity']].drop_duplicates().groupby( 'customerid' ).sum().reset_index().rename( columns={'quantity':'qtd_items'})\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customerid', how='left' ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = returns[['customerid', 'quantity']].drop_duplicates().groupby( 'customerid' ).sum().reset_index().rename( columns={'quantity':'qtd_items_return'})\n",
    "df_freq['qtd_items_return'] = df_freq['qtd_items_return']*-1\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customerid', how='left' ).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 avg ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid          0\n",
       "gross_revenue       0\n",
       "gross_returns       0\n",
       "recencydays         0\n",
       "qtd_items           0\n",
       "qtd_items_return    0\n",
       "avg_ticket          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ref['avg_ticket']=df_ref['gross_revenue']/(df_ref['qtd_items']-df_ref['qtd_items_return'])\n",
    "df_ref['avg_ticket']=df_ref['avg_ticket'].replace([np.inf, -np.inf], 0) \n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid          0\n",
       "gross_revenue       0\n",
       "gross_returns       0\n",
       "recencydays         0\n",
       "qtd_items           0\n",
       "qtd_items_return    0\n",
       "avg_ticket          0\n",
       "frequency           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency\n",
    "\n",
    "df_aux = ( df2[['customerid', 'invoiceno', 'invoicedate']].drop_duplicates()\n",
    "                                                        .groupby('customerid')\n",
    "                                                        .agg( max_ = ('invoicedate', 'max'),\n",
    "                                                            min_= ('invoicedate', 'min'),\n",
    "                                                            days_= ('invoicedate', lambda x: (( x.max() - x.min()).days ) +1 ),\n",
    "                                                            buy_ = ('invoiceno', 'count')).reset_index()\n",
    ")\n",
    "\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply(lambda x: x['buy_']/x['days_'] if x['days_'] != 0 else 0, axis=1)\n",
    "\n",
    "df_ref= df_ref.merge(df_aux[['customerid','frequency']], on='customerid', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 basket size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid             0\n",
       "gross_revenue          0\n",
       "gross_returns          0\n",
       "recencydays            0\n",
       "qtd_items              0\n",
       "qtd_items_return       0\n",
       "avg_ticket             0\n",
       "frequency              0\n",
       "avg_basket_size     1336\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = ( purchases.loc[:, ['customerid', 'invoiceno', 'quantity']].groupby( 'customerid' )\n",
    "                                                                            .agg( n_purchase=( 'invoiceno', 'nunique'),\n",
    "                                                                                  n_products=( 'quantity', 'sum' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customerid', 'avg_basket_size']], how='left', on='customerid' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 nunique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerid               0\n",
      "gross_revenue            0\n",
      "gross_returns            0\n",
      "recencydays              0\n",
      "qtd_items                0\n",
      "qtd_items_return         0\n",
      "avg_ticket               0\n",
      "frequency                0\n",
      "avg_basket_size       1336\n",
      "n_purchases_unique    1336\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>gross_returns</th>\n",
       "      <th>recencydays</th>\n",
       "      <th>qtd_items</th>\n",
       "      <th>qtd_items_return</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>n_purchases_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>5391.21</td>\n",
       "      <td>102.58</td>\n",
       "      <td>372.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>385.086429</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>50.970588</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047</td>\n",
       "      <td>3237.54</td>\n",
       "      <td>158.44</td>\n",
       "      <td>31.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.694762</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>139.100000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583</td>\n",
       "      <td>7281.38</td>\n",
       "      <td>94.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.793535</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>337.333333</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13748</td>\n",
       "      <td>948.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.610947</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>87.800000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15100</td>\n",
       "      <td>876.00</td>\n",
       "      <td>240.90</td>\n",
       "      <td>333.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.692308</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gross_revenue  gross_returns  recencydays  qtd_items  \\\n",
       "0       17850        5391.21         102.58        372.0       35.0   \n",
       "1       13047        3237.54         158.44         31.0      132.0   \n",
       "2       12583        7281.38          94.04          2.0     1569.0   \n",
       "3       13748         948.25           0.00         95.0      169.0   \n",
       "4       15100         876.00         240.90        333.0       48.0   \n",
       "\n",
       "   qtd_items_return  avg_ticket  frequency  avg_basket_size  \\\n",
       "0              21.0  385.086429  17.000000        50.970588   \n",
       "1               6.0   25.694762   0.029155       139.100000   \n",
       "2              50.0    4.793535   0.040323       337.333333   \n",
       "3               0.0    5.610947   0.017921        87.800000   \n",
       "4              22.0   33.692308   0.073171        26.666667   \n",
       "\n",
       "   n_purchases_unique  \n",
       "0                34.0  \n",
       "1                10.0  \n",
       "2                15.0  \n",
       "3                 5.0  \n",
       "4                 3.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basket size\n",
    "df_aux = ( purchases.groupby('customerid').agg( n_purchases_unique = ('invoiceno','nunique'), n_products = ('quantity','sum'))\n",
    "                                            .reset_index()\n",
    ")\n",
    "#calculation\n",
    "df_ref = df_ref.merge( df_aux[['customerid', 'n_purchases_unique']], how='left', on='customerid')\n",
    "print(df_ref.isna().sum())\n",
    "\n",
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Filters Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7853, 10)\n",
      "(5721, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df5.shape)\n",
    "df5=df5[df5['customerid']!=16446]\n",
    "df5=df5[df5['customerid']!=14646]\n",
    "df5=df5[df5['avg_ticket']>0]\n",
    "df5['avg_ticket']=df5['avg_ticket'].fillna(0)\n",
    "print(df5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_cols=[ 'recencydays',\n",
    "        'avg_ticket', 'frequency',\n",
    "       'avg_basket_size', 'n_purchases_unique']\n",
    "\n",
    "rs_cols=['gross_revenue', 'gross_returns', \n",
    "       'qtd_items', 'qtd_items_return',]\n",
    "       \n",
    "for i in mms_cols:\n",
    "     mms=pd.read_pickle(f\"artifacts/{i}_minmax.pkl\")\n",
    "     df5[[i]] = mms.transform(df5[[i]])\n",
    "\n",
    "for i in rs_cols:\n",
    "     kb=pd.read_pickle(f\"artifacts/{i}_robust.pkl\")\n",
    "     df5[[i]] = kb.transform(df5[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0  Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df5.drop(columns=['customerid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>gross_returns</th>\n",
       "      <th>recencydays</th>\n",
       "      <th>qtd_items</th>\n",
       "      <th>qtd_items_return</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>n_purchases_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.997319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.043062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.066986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.019139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.892761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gross_revenue  gross_returns  recencydays  qtd_items  qtd_items_return  \\\n",
       "0            3.0            2.0     0.997319        0.0               2.0   \n",
       "1            2.0            2.0     0.083110        1.0               1.0   \n",
       "2            3.0            2.0     0.005362        3.0               2.0   \n",
       "3            1.0            0.0     0.254692        1.0               0.0   \n",
       "4            1.0            2.0     0.892761        0.0               2.0   \n",
       "\n",
       "   avg_ticket  frequency  avg_basket_size  n_purchases_unique  \n",
       "0    0.028434   1.000000         0.003532            0.157895  \n",
       "1    0.001893   0.001395         0.009761            0.043062  \n",
       "2    0.000350   0.002052         0.023773            0.066986  \n",
       "3    0.000410   0.000734         0.006135            0.019139  \n",
       "4    0.002484   0.003985         0.001814            0.009569  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#km = pd.read_pickle(f\"s3://insiders-clustering-deploy/artifacts/model.pkl\")\n",
    "km = pd.read_pickle(f\"artifacts/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5eab_row0_col6, #T_f5eab_row1_col8, #T_f5eab_row2_col1, #T_f5eab_row2_col2, #T_f5eab_row2_col4, #T_f5eab_row2_col5, #T_f5eab_row2_col9, #T_f5eab_row3_col0, #T_f5eab_row3_col3, #T_f5eab_row3_col7 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5eab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5eab_level0_col0\" class=\"col_heading level0 col0\" >customerid</th>\n",
       "      <th id=\"T_f5eab_level0_col1\" class=\"col_heading level0 col1\" >gross_revenue</th>\n",
       "      <th id=\"T_f5eab_level0_col2\" class=\"col_heading level0 col2\" >gross_returns</th>\n",
       "      <th id=\"T_f5eab_level0_col3\" class=\"col_heading level0 col3\" >recencydays</th>\n",
       "      <th id=\"T_f5eab_level0_col4\" class=\"col_heading level0 col4\" >qtd_items</th>\n",
       "      <th id=\"T_f5eab_level0_col5\" class=\"col_heading level0 col5\" >qtd_items_return</th>\n",
       "      <th id=\"T_f5eab_level0_col6\" class=\"col_heading level0 col6\" >avg_ticket</th>\n",
       "      <th id=\"T_f5eab_level0_col7\" class=\"col_heading level0 col7\" >frequency</th>\n",
       "      <th id=\"T_f5eab_level0_col8\" class=\"col_heading level0 col8\" >avg_basket_size</th>\n",
       "      <th id=\"T_f5eab_level0_col9\" class=\"col_heading level0 col9\" >n_purchases_unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >cluster</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5eab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5eab_row0_col0\" class=\"data row0 col0\" >33151.182122</td>\n",
       "      <td id=\"T_f5eab_row0_col1\" class=\"data row0 col1\" >1.162907</td>\n",
       "      <td id=\"T_f5eab_row0_col2\" class=\"data row0 col2\" >0.000835</td>\n",
       "      <td id=\"T_f5eab_row0_col3\" class=\"data row0 col3\" >0.248913</td>\n",
       "      <td id=\"T_f5eab_row0_col4\" class=\"data row0 col4\" >1.524645</td>\n",
       "      <td id=\"T_f5eab_row0_col5\" class=\"data row0 col5\" >0.088555</td>\n",
       "      <td id=\"T_f5eab_row0_col6\" class=\"data row0 col6\" >0.002258</td>\n",
       "      <td id=\"T_f5eab_row0_col7\" class=\"data row0 col7\" >0.023924</td>\n",
       "      <td id=\"T_f5eab_row0_col8\" class=\"data row0 col8\" >0.027926</td>\n",
       "      <td id=\"T_f5eab_row0_col9\" class=\"data row0 col9\" >0.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5eab_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5eab_row1_col0\" class=\"data row1 col0\" >27432.065217</td>\n",
       "      <td id=\"T_f5eab_row1_col1\" class=\"data row1 col1\" >2.297101</td>\n",
       "      <td id=\"T_f5eab_row1_col2\" class=\"data row1 col2\" >0.524155</td>\n",
       "      <td id=\"T_f5eab_row1_col3\" class=\"data row1 col3\" >0.149214</td>\n",
       "      <td id=\"T_f5eab_row1_col4\" class=\"data row1 col4\" >2.487923</td>\n",
       "      <td id=\"T_f5eab_row1_col5\" class=\"data row1 col5\" >0.700483</td>\n",
       "      <td id=\"T_f5eab_row1_col6\" class=\"data row1 col6\" >0.000758</td>\n",
       "      <td id=\"T_f5eab_row1_col7\" class=\"data row1 col7\" >0.014378</td>\n",
       "      <td id=\"T_f5eab_row1_col8\" class=\"data row1 col8\" >0.050756</td>\n",
       "      <td id=\"T_f5eab_row1_col9\" class=\"data row1 col9\" >0.030546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5eab_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5eab_row2_col0\" class=\"data row2 col0\" >15021.892989</td>\n",
       "      <td id=\"T_f5eab_row2_col1\" class=\"data row2 col1\" >2.590406</td>\n",
       "      <td id=\"T_f5eab_row2_col2\" class=\"data row2 col2\" >1.874539</td>\n",
       "      <td id=\"T_f5eab_row2_col3\" class=\"data row2 col3\" >0.065520</td>\n",
       "      <td id=\"T_f5eab_row2_col4\" class=\"data row2 col4\" >2.571956</td>\n",
       "      <td id=\"T_f5eab_row2_col5\" class=\"data row2 col5\" >1.837638</td>\n",
       "      <td id=\"T_f5eab_row2_col6\" class=\"data row2 col6\" >0.001246</td>\n",
       "      <td id=\"T_f5eab_row2_col7\" class=\"data row2 col7\" >0.004073</td>\n",
       "      <td id=\"T_f5eab_row2_col8\" class=\"data row2 col8\" >0.030634</td>\n",
       "      <td id=\"T_f5eab_row2_col9\" class=\"data row2 col9\" >0.085401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5eab_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5eab_row3_col0\" class=\"data row3 col0\" >36651.451502</td>\n",
       "      <td id=\"T_f5eab_row3_col1\" class=\"data row3 col1\" >0.107322</td>\n",
       "      <td id=\"T_f5eab_row3_col2\" class=\"data row3 col2\" >0.045682</td>\n",
       "      <td id=\"T_f5eab_row3_col3\" class=\"data row3 col3\" >0.407103</td>\n",
       "      <td id=\"T_f5eab_row3_col4\" class=\"data row3 col4\" >0.151126</td>\n",
       "      <td id=\"T_f5eab_row3_col5\" class=\"data row3 col5\" >0.078223</td>\n",
       "      <td id=\"T_f5eab_row3_col6\" class=\"data row3 col6\" >0.000907</td>\n",
       "      <td id=\"T_f5eab_row3_col7\" class=\"data row3 col7\" >0.044271</td>\n",
       "      <td id=\"T_f5eab_row3_col8\" class=\"data row3 col8\" >0.008118</td>\n",
       "      <td id=\"T_f5eab_row3_col9\" class=\"data row3 col9\" >0.002328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5eab_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5eab_row4_col0\" class=\"data row4 col0\" >15195.172628</td>\n",
       "      <td id=\"T_f5eab_row4_col1\" class=\"data row4 col1\" >0.973561</td>\n",
       "      <td id=\"T_f5eab_row4_col2\" class=\"data row4 col2\" >1.236392</td>\n",
       "      <td id=\"T_f5eab_row4_col3\" class=\"data row4 col3\" >0.179979</td>\n",
       "      <td id=\"T_f5eab_row4_col4\" class=\"data row4 col4\" >0.961120</td>\n",
       "      <td id=\"T_f5eab_row4_col5\" class=\"data row4 col5\" >1.307932</td>\n",
       "      <td id=\"T_f5eab_row4_col6\" class=\"data row4 col6\" >0.001188</td>\n",
       "      <td id=\"T_f5eab_row4_col7\" class=\"data row4 col7\" >0.009691</td>\n",
       "      <td id=\"T_f5eab_row4_col8\" class=\"data row4 col8\" >0.013881</td>\n",
       "      <td id=\"T_f5eab_row4_col9\" class=\"data row4 col9\" >0.017814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20f4561ae60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=df5.copy()\n",
    "df8['cluster']=km.predict(df8.drop('customerid', axis=1))\n",
    "df8.groupby('cluster').mean().style.highlight_max( color='green', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>gross_returns</th>\n",
       "      <th>recencydays</th>\n",
       "      <th>qtd_items</th>\n",
       "      <th>qtd_items_return</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>n_purchases_unique</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.997319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.043062</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.066986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gross_revenue  gross_returns  recencydays  qtd_items  \\\n",
       "0       17850            3.0            2.0     0.997319        0.0   \n",
       "1       13047            2.0            2.0     0.083110        1.0   \n",
       "2       12583            3.0            2.0     0.005362        3.0   \n",
       "\n",
       "   qtd_items_return  avg_ticket  frequency  avg_basket_size  \\\n",
       "0               2.0    0.028434   1.000000         0.003532   \n",
       "1               1.0    0.001893   0.001395         0.009761   \n",
       "2               2.0    0.000350   0.002052         0.023773   \n",
       "\n",
       "   n_purchases_unique  cluster  \n",
       "0            0.157895        4  \n",
       "1            0.043062        4  \n",
       "2            0.066986        2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9=df8.copy()\n",
    "df9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['recencydays','qtd_items','qtd_items_return']:\n",
    "    df9[i]=df9[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = f\"postgresql://dbfinal:dbfinal2@dbfinal.cegm6m2znhnj.sa-east-1.rds.amazonaws.com/postgres\"\n",
    "\n",
    "conn = create_engine( endpoint)\n",
    "\n",
    "\n",
    " #create table\n",
    "query_create_table_insiders = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS insiders ( \n",
    "       grossrevenue   REAL,\n",
    "       gross_returns    REAL,\n",
    "       recencydays    REAL,   \n",
    "       qtd_items   REAL,\n",
    "       qtd_items_return     REAL,\n",
    "       avg_ticket   REAL,\n",
    "       frequency       REAL,\n",
    "       avg_basket_size  REAL,\n",
    "       n_purchases_unique   REAL,\n",
    "       cluster         INTEGER\n",
    "   )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "conn.execute( query_create_table_insiders )\n",
    "#conn.commit()\n",
    "#conn.close()\n",
    "\n",
    "# insert data\n",
    "df9.to_sql( 'insiders', con=conn, if_exists='replace', index=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>gross_returns</th>\n",
       "      <th>recencydays</th>\n",
       "      <th>qtd_items</th>\n",
       "      <th>qtd_items_return</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>n_purchases_unique</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.043062</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.066986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gross_revenue  gross_returns  recencydays  qtd_items  \\\n",
       "0       17850            3.0            2.0            0          0   \n",
       "1       13047            2.0            2.0            0          1   \n",
       "2       12583            3.0            2.0            0          3   \n",
       "3       13748            1.0            0.0            0          1   \n",
       "4       15100            1.0            2.0            0          0   \n",
       "\n",
       "   qtd_items_return  avg_ticket  frequency  avg_basket_size  \\\n",
       "0                 2    0.028434   1.000000         0.003532   \n",
       "1                 1    0.001893   0.001395         0.009761   \n",
       "2                 2    0.000350   0.002052         0.023773   \n",
       "3                 0    0.000410   0.000734         0.006135   \n",
       "4                 2    0.002484   0.003985         0.001814   \n",
       "\n",
       "   n_purchases_unique  cluster  \n",
       "0            0.157895        4  \n",
       "1            0.043062        4  \n",
       "2            0.066986        2  \n",
       "3            0.019139        0  \n",
       "4            0.009569        4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get query\n",
    "\n",
    "query_collect = \"\"\"\n",
    "SELECT * FROM insiders\n",
    "\"\"\"\n",
    "\n",
    "df=pd.read_sql_query( query_collect, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.clear_compiled_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rodou tudo\n"
     ]
    }
   ],
   "source": [
    "print('rodou tudo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('automl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "25221b6b9a4d399886f2cc4863e60b0fd11067ce172b33ecf50faf510e9d19c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
