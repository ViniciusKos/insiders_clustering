{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Value Customer Identification (Insiders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler,MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re, pickle, s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (p:\\python\\github\\insiders_clustering\\venv_10\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list --format=freeze > requirements_production.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_key_id = os.environ.get( \"AWS_ACCESS_KEY_ID\" )\n",
    "aws_key_secret = os.environ.get( \"AWS_SECRET_ACCESS_KEY\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = pd.read_csv(\"../../cred.csv\", encoding='latin1')\n",
    "aws_key_id = cred[\"Access key ID\"][0]\n",
    "aws_key_secret = cred[\"Secret access key\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoiceno</th>\n",
       "      <th>stockcode</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoicedate</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>customerid</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  invoiceno stockcode                         description  quantity  \\\n",
       "0    536365    85123A  WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                 WHITE METAL LANTERN         6   \n",
       "2    536365    84406B      CREAM CUPID HEARTS COAT HANGER         8   \n",
       "\n",
       "      invoicedate  unitprice  customerid         country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_csv('s3://insiders-clustering-deploy/data.csv', storage_options={ \"key\":aws_key_id,\n",
    "                                                                                 \"secret\":aws_key_secret}, encoding='latin1')\n",
    "#df0 = pd.read_parquet('data.parquet')\n",
    "#df0 = pd.read_csv('data.csv')                                                                                                \n",
    "df0.columns=df0.columns.str.lower()\n",
    "df0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing=df1[df1['customerid'].isna()]\n",
    "df_not_missing=df1[~df1['customerid'].isna()]\n",
    "df_missing[df_missing['invoiceno'].isin(df_not_missing['invoiceno'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reference\n",
    "df_backup = pd.DataFrame( df_missing['invoiceno'].drop_duplicates())\n",
    "df_backup['customerid']=np.arange(80000, 80000+len( df_backup ), 1)\n",
    "\n",
    "# merge original with reference datafarme\n",
    "df1 = df1.merge(df_backup, on='invoiceno', how='left')\n",
    "\n",
    "#coalesce\n",
    "df1['customerid']=df1['customerid_x'].combine_first( df1['customerid_y'])\n",
    "\n",
    "#drop extra columns\n",
    "df1 = df1.drop( columns=['customerid_x','customerid_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 data types treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['invoicedate']=df1['invoicedate'].str.split(expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['invoicedate'] = pd.to_datetime( df1['invoicedate'], format=\"%m/%d/%Y\",errors='coerce')\n",
    "df1['customerid'] = df1['customerid'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Feature Filtering/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532618, 8)\n"
     ]
    }
   ],
   "source": [
    " # ----------------------  Numerical attributes ----------------\n",
    " # purhcases df and returns df\n",
    "returns = df2.loc[df2['quantity'] < 0, :]\n",
    "purchases = df2.loc[df2['quantity'] >= 0, :]\n",
    "\n",
    "\n",
    "#drop invoices with only letters\n",
    "df2=df2[~df2['invoiceno'].str.contains('[^0-9]+', na=False)]\n",
    "\n",
    "#filter only stockcodes with numbers\n",
    "#df2=df2[df2['stockcode'].str.contains('[0-9]+', na=False)]\n",
    "print(df2.shape)\n",
    "\n",
    "\n",
    "# ------------------ Categorical attributes -------------------\n",
    "# drop description\n",
    "df2 = df2.drop( columns='description', axis=1 )\n",
    "\n",
    "# drop \"unspecifiec\" and \"european communoty\" countries -  \n",
    "df2 = df2[~df2['country'].isin( [\"European Community\",'Unspecified' ] ) ]\n",
    "\n",
    "\n",
    "# --------------------- Filter bad customer ----------------- (Section 5 Exploratory Data Analysis)\n",
    "df2=df2[df2['customerid']!=16446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref=df2[['customerid']].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 profit (gross revenue - gross outgoings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gross revenue\n",
    "purchases['gross_revenue'] = purchases['quantity'] * purchases['unitprice']\n",
    "df_monetary = purchases[['customerid', 'gross_revenue']].groupby( 'customerid').sum().reset_index()\n",
    "df_ref=df_ref.merge(df_monetary,on='customerid',how='left').fillna(0)\n",
    "\n",
    "\n",
    "# gross outgoings\n",
    "returns['gross_returns'] = returns['quantity'] * returns['unitprice']*-1\n",
    "df_returns = returns[['customerid', 'gross_returns']].groupby( 'customerid').sum().reset_index()\n",
    "df_ref=df_ref.merge(df_returns,on='customerid',how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recency\n",
    "df_recency = purchases.groupby( 'customerid').max().reset_index()\n",
    "df_recency['recencydays'] = ( purchases['invoicedate'].max() - df_recency['invoicedate'] ).dt.days\n",
    "df_recency= df_recency[['customerid','recencydays']].copy()\n",
    "df_ref=df_ref.merge(df_recency, how='left', on='customerid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 quantity of items kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity of products purchased\n",
    "df_freq = purchases[['customerid', 'quantity']].drop_duplicates().groupby( 'customerid' ).sum().reset_index().rename( columns={'quantity':'qtd_items'})\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customerid', how='left' ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = returns[['customerid', 'quantity']].drop_duplicates().groupby( 'customerid' ).sum().reset_index().rename( columns={'quantity':'qtd_items_return'})\n",
    "df_freq['qtd_items_return'] = df_freq['qtd_items_return']*-1\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customerid', how='left' ).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 avg ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid          0\n",
       "gross_revenue       0\n",
       "gross_returns       0\n",
       "recencydays         0\n",
       "qtd_items           0\n",
       "qtd_items_return    0\n",
       "avg_ticket          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ref['avg_ticket']=df_ref['gross_revenue']/(df_ref['qtd_items']-df_ref['qtd_items_return'])\n",
    "df_ref['avg_ticket']=df_ref['avg_ticket'].replace([np.inf, -np.inf], 0) \n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid          0\n",
       "gross_revenue       0\n",
       "gross_returns       0\n",
       "recencydays         0\n",
       "qtd_items           0\n",
       "qtd_items_return    0\n",
       "avg_ticket          0\n",
       "frequency           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency\n",
    "\n",
    "df_aux = ( df2[['customerid', 'invoiceno', 'invoicedate']].drop_duplicates()\n",
    "                                                        .groupby('customerid')\n",
    "                                                        .agg( max_ = ('invoicedate', 'max'),\n",
    "                                                            min_= ('invoicedate', 'min'),\n",
    "                                                            days_= ('invoicedate', lambda x: (( x.max() - x.min()).days ) +1 ),\n",
    "                                                            buy_ = ('invoiceno', 'count')).reset_index()\n",
    ")\n",
    "\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply(lambda x: x['buy_']/x['days_'] if x['days_'] != 0 else 0, axis=1)\n",
    "\n",
    "df_ref= df_ref.merge(df_aux[['customerid','frequency']], on='customerid', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 basket size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid             0\n",
       "gross_revenue          0\n",
       "gross_returns          0\n",
       "recencydays            0\n",
       "qtd_items              0\n",
       "qtd_items_return       0\n",
       "avg_ticket             0\n",
       "frequency              0\n",
       "avg_basket_size     1336\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = ( purchases.loc[:, ['customerid', 'invoiceno', 'quantity']].groupby( 'customerid' )\n",
    "                                                                            .agg( n_purchase=( 'invoiceno', 'nunique'),\n",
    "                                                                                  n_products=( 'quantity', 'sum' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customerid', 'avg_basket_size']], how='left', on='customerid' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 nunique items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerid               0\n",
      "gross_revenue            0\n",
      "gross_returns            0\n",
      "recencydays              0\n",
      "qtd_items                0\n",
      "qtd_items_return         0\n",
      "avg_ticket               0\n",
      "frequency                0\n",
      "avg_basket_size       1336\n",
      "n_purchases_unique    1336\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>gross_returns</th>\n",
       "      <th>recencydays</th>\n",
       "      <th>qtd_items</th>\n",
       "      <th>qtd_items_return</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>n_purchases_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>5391.21</td>\n",
       "      <td>102.58</td>\n",
       "      <td>372.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>385.086429</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>50.970588</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047</td>\n",
       "      <td>3237.54</td>\n",
       "      <td>158.44</td>\n",
       "      <td>31.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.694762</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>139.100000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583</td>\n",
       "      <td>7281.38</td>\n",
       "      <td>94.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.793535</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>337.333333</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13748</td>\n",
       "      <td>948.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.610947</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>87.800000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15100</td>\n",
       "      <td>876.00</td>\n",
       "      <td>240.90</td>\n",
       "      <td>333.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.692308</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gross_revenue  gross_returns  recencydays  qtd_items  \\\n",
       "0       17850        5391.21         102.58        372.0       35.0   \n",
       "1       13047        3237.54         158.44         31.0      132.0   \n",
       "2       12583        7281.38          94.04          2.0     1569.0   \n",
       "3       13748         948.25           0.00         95.0      169.0   \n",
       "4       15100         876.00         240.90        333.0       48.0   \n",
       "\n",
       "   qtd_items_return  avg_ticket  frequency  avg_basket_size  \\\n",
       "0              21.0  385.086429  17.000000        50.970588   \n",
       "1               6.0   25.694762   0.029155       139.100000   \n",
       "2              50.0    4.793535   0.040323       337.333333   \n",
       "3               0.0    5.610947   0.017921        87.800000   \n",
       "4              22.0   33.692308   0.073171        26.666667   \n",
       "\n",
       "   n_purchases_unique  \n",
       "0                34.0  \n",
       "1                10.0  \n",
       "2                15.0  \n",
       "3                 5.0  \n",
       "4                 3.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basket size\n",
    "df_aux = ( purchases.groupby('customerid').agg( n_purchases_unique = ('invoiceno','nunique'), n_products = ('quantity','sum'))\n",
    "                                            .reset_index()\n",
    ")\n",
    "#calculation\n",
    "df_ref = df_ref.merge( df_aux[['customerid', 'n_purchases_unique']], how='left', on='customerid')\n",
    "print(df_ref.isna().sum())\n",
    "\n",
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Filters Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7853, 10)\n",
      "(5721, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df5.shape)\n",
    "df5=df5[df5['customerid']!=16446]\n",
    "df5=df5[df5['customerid']!=14646]\n",
    "df5=df5[df5['avg_ticket']>0]\n",
    "df5['avg_ticket']=df5['avg_ticket'].fillna(0)\n",
    "print(df5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5721, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_cols=[ 'recencydays','avg_ticket', 'frequency','avg_basket_size', 'n_purchases_unique','gross_revenue', 'gross_returns', 'qtd_items', 'qtd_items_return']\n",
    "\n",
    "       \n",
    "for i in mms_cols:\n",
    "     try:\n",
    "          mms=pd.read_pickle(f\"artifacts/{i}_minmax.pkl\")\n",
    "          df5[[i]] = mms.transform(df5[[i]])\n",
    "     except:\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerid            31815.820311\n",
       "gross_revenue             0.006721\n",
       "gross_returns             0.001611\n",
       "recencydays               0.313635\n",
       "qtd_items                 0.005998\n",
       "qtd_items_return          0.002282\n",
       "avg_ticket                0.001227\n",
       "frequency                 0.032060\n",
       "avg_basket_size           0.019203\n",
       "n_purchases_unique        0.011766\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0  Umap Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "uma=pd.read_pickle(f\"artifacts/umap_reducer.pkl\")\n",
    "km = pd.read_pickle(f\"artifacts/model.pkl\")\n",
    "df5 = uma.transform(df5.drop(columns=[\"customerid\"]))\n",
    "X = pd.DataFrame( df5, columns=['embedding_x', 'embedding_y'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd379_row0_col0, #T_fd379_row2_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd379\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd379_level0_col0\" class=\"col_heading level0 col0\" >embedding_x</th>\n",
       "      <th id=\"T_fd379_level0_col1\" class=\"col_heading level0 col1\" >embedding_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >cluster</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd379_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd379_row0_col0\" class=\"data row0 col0\" >18.015882</td>\n",
       "      <td id=\"T_fd379_row0_col1\" class=\"data row0 col1\" >-6.805203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd379_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fd379_row1_col0\" class=\"data row1 col0\" >-6.276211</td>\n",
       "      <td id=\"T_fd379_row1_col1\" class=\"data row1 col1\" >9.749448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd379_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fd379_row2_col0\" class=\"data row2 col0\" >10.413925</td>\n",
       "      <td id=\"T_fd379_row2_col1\" class=\"data row2 col1\" >17.871540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd379_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fd379_row3_col0\" class=\"data row3 col0\" >-3.847560</td>\n",
       "      <td id=\"T_fd379_row3_col1\" class=\"data row3 col1\" >-3.597263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd379_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fd379_row4_col0\" class=\"data row4 col0\" >1.095944</td>\n",
       "      <td id=\"T_fd379_row4_col1\" class=\"data row4 col1\" >14.835188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd379_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fd379_row5_col0\" class=\"data row5 col0\" >4.575210</td>\n",
       "      <td id=\"T_fd379_row5_col1\" class=\"data row5 col1\" >3.833500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x116db602980>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = X.copy()\n",
    "df8['cluster'] = km.predict(df8)\n",
    "df8.groupby('cluster').mean().style.highlight_max( color='green', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_x</th>\n",
       "      <th>embedding_y</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.758257</td>\n",
       "      <td>-6.846011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.724231</td>\n",
       "      <td>-3.071228</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.886896</td>\n",
       "      <td>-5.512192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_x  embedding_y  cluster\n",
       "0    17.758257    -6.846011        0\n",
       "1    -2.724231    -3.071228        3\n",
       "2    -3.886896    -5.512192        3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9=df8.copy()\n",
    "df9.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'recencydays'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recencydays'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\cluster_deploy.ipynb Cell 45\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mrecencydays\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mqtd_items\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mqtd_items_return\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df9[i]\u001b[39m=\u001b[39mdf9[i]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recencydays'"
     ]
    }
   ],
   "source": [
    "#for i in ['recencydays','qtd_items','qtd_items_return']:\n",
    "#    df9[i]=df9[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) could not translate host name \"dbfinal.cegm6m2znhnj.sa-east-1.rds.amazonaws.com\" to address: Unknown host\n\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3361\u001b[0m, in \u001b[0;36mEngine._wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:320\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \n\u001b[0;32m    315\u001b[0m \u001b[39mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m \n\u001b[0;32m    319\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m \u001b[39mreturn\u001b[39;00m _ConnectionFairy\u001b[39m.\u001b[39;49m_checkout(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:884\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fairy:\n\u001b[1;32m--> 884\u001b[0m     fairy \u001b[39m=\u001b[39m _ConnectionRecord\u001b[39m.\u001b[39;49mcheckout(pool)\n\u001b[0;32m    886\u001b[0m     fairy\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m pool\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:486\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheckout\u001b[39m(\u001b[39mcls\u001b[39m, pool):\n\u001b[1;32m--> 486\u001b[0m     rec \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_do_get()\n\u001b[0;32m    487\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:145\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m    146\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dec_overflow()\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_only:\n\u001b[1;32m---> 70\u001b[0m         compat\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m     71\u001b[0m             exc_value,\n\u001b[0;32m     72\u001b[0m             with_traceback\u001b[39m=\u001b[39;49mexc_tb,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:143\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection()\n\u001b[0;32m    144\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:266\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[39mreturn\u001b[39;00m _ConnectionRecord(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:381\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m connect:\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__connect()\n\u001b[0;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize_callback \u001b[39m=\u001b[39m deque()\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:677\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 677\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m    678\u001b[0m         pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mError on connect(): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_only:\n\u001b[1;32m---> 70\u001b[0m         compat\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m     71\u001b[0m             exc_value,\n\u001b[0;32m     72\u001b[0m             with_traceback\u001b[39m=\u001b[39;49mexc_tb,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:673\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 673\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi_connection \u001b[39m=\u001b[39m connection \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_invoke_creator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    674\u001b[0m pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreated new connection \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, connection)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\create.py:578\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[39mreturn\u001b[39;00m connection\n\u001b[1;32m--> 578\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\default.py:598\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams):\n\u001b[0;32m    597\u001b[0m     \u001b[39m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m dsn \u001b[39m=\u001b[39m _ext\u001b[39m.\u001b[39mmake_dsn(dsn, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[39m=\u001b[39m _connect(dsn, connection_factory\u001b[39m=\u001b[39mconnection_factory, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m cursor_factory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"dbfinal.cegm6m2znhnj.sa-east-1.rds.amazonaws.com\" to address: Unknown host\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\cluster_deploy.ipynb Cell 46\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m  \u001b[39m#create table\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m query_create_table_insiders \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m    CREATE TABLE IF NOT EXISTS insiders ( \u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m       grossrevenue   REAL,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m   )\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m conn\u001b[39m.\u001b[39;49mexecute( query_create_table_insiders )\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#conn.commit()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#conn.close()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# insert data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Python/GitHub/insiders_clustering/cluster_deploy.ipynb#X63sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df9\u001b[39m.\u001b[39mto_sql( \u001b[39m'\u001b[39m\u001b[39minsiders\u001b[39m\u001b[39m'\u001b[39m, con\u001b[39m=\u001b[39mconn, if_exists\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m )\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py:402\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_warning:\n\u001b[0;32m    401\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m--> 402\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3256\u001b[0m, in \u001b[0;36mEngine.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   3230\u001b[0m \u001b[39m@util\u001b[39m\u001b[39m.\u001b[39mdeprecated_20(\n\u001b[0;32m   3231\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m:meth:`_engine.Engine.execute`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3232\u001b[0m     alternative\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll statement execution in SQLAlchemy 2.0 is performed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3237\u001b[0m )\n\u001b[0;32m   3238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, statement, \u001b[39m*\u001b[39mmultiparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m   3239\u001b[0m     \u001b[39m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[0;32m   3240\u001b[0m \u001b[39m    :class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[0;32m   3241\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3254\u001b[0m \n\u001b[0;32m   3255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3256\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect(close_with_result\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   3257\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39mexecute(statement, \u001b[39m*\u001b[39mmultiparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3315\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self, close_with_result)\u001b[0m\n\u001b[0;32m   3300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, close_with_result\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   3301\u001b[0m     \u001b[39m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3302\u001b[0m \n\u001b[0;32m   3303\u001b[0m \u001b[39m    The :class:`_engine.Connection` object is a facade that uses a DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3312\u001b[0m \n\u001b[0;32m   3313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection_cls(\u001b[39mself\u001b[39;49m, close_with_result\u001b[39m=\u001b[39;49mclose_with_result)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:96\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, close_with_result, _branch_from, _execution_options, _dispatch, _has_events, _allow_revalidate)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39m=\u001b[39m _branch_from\u001b[39m.\u001b[39m_has_events\n\u001b[0;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbapi_connection \u001b[39m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m         connection\n\u001b[0;32m     95\u001b[0m         \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m         \u001b[39melse\u001b[39;00m engine\u001b[39m.\u001b[39;49mraw_connection()\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_transaction \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__savepoint_seq \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3394\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self, _connection)\u001b[0m\n\u001b[0;32m   3372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraw_connection\u001b[39m(\u001b[39mself\u001b[39m, _connection\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3373\u001b[0m     \u001b[39m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3374\u001b[0m \n\u001b[0;32m   3375\u001b[0m \u001b[39m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3392\u001b[0m \n\u001b[0;32m   3393\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3394\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrap_pool_connect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool\u001b[39m.\u001b[39;49mconnect, _connection)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3364\u001b[0m, in \u001b[0;36mEngine._wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3363\u001b[0m     \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 3364\u001b[0m         Connection\u001b[39m.\u001b[39;49m_handle_dbapi_exception_noconnection(\n\u001b[0;32m   3365\u001b[0m             e, dialect, \u001b[39mself\u001b[39;49m\n\u001b[0;32m   3366\u001b[0m         )\n\u001b[0;32m   3367\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3368\u001b[0m         util\u001b[39m.\u001b[39mraise_(\n\u001b[0;32m   3369\u001b[0m             sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[0;32m   3370\u001b[0m         )\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2198\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine)\u001b[0m\n\u001b[0;32m   2196\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[0;32m   2197\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2198\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m   2199\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[0;32m   2200\u001b[0m     )\n\u001b[0;32m   2201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2202\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3361\u001b[0m, in \u001b[0;36mEngine._wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3359\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m dialect\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3363\u001b[0m     \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:320\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    313\u001b[0m     \u001b[39m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \n\u001b[0;32m    315\u001b[0m \u001b[39m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    318\u001b[0m \n\u001b[0;32m    319\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConnectionFairy\u001b[39m.\u001b[39;49m_checkout(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:884\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    882\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_checkout\u001b[39m(\u001b[39mcls\u001b[39m, pool, threadconns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fairy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    883\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fairy:\n\u001b[1;32m--> 884\u001b[0m         fairy \u001b[39m=\u001b[39m _ConnectionRecord\u001b[39m.\u001b[39;49mcheckout(pool)\n\u001b[0;32m    886\u001b[0m         fairy\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m pool\n\u001b[0;32m    887\u001b[0m         fairy\u001b[39m.\u001b[39m_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:486\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheckout\u001b[39m(\u001b[39mcls\u001b[39m, pool):\n\u001b[1;32m--> 486\u001b[0m     rec \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_do_get()\n\u001b[0;32m    487\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m         dbapi_connection \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mget_connection()\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:145\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection()\n\u001b[0;32m    144\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m    146\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dec_overflow()\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_only:\n\u001b[1;32m---> 70\u001b[0m         compat\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m     71\u001b[0m             exc_value,\n\u001b[0;32m     72\u001b[0m             with_traceback\u001b[39m=\u001b[39;49mexc_tb,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m compat\u001b[39m.\u001b[39mpy3k \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info[\u001b[39m1\u001b[39m]:\n\u001b[0;32m     76\u001b[0m         \u001b[39m# emulate Py3K's behavior of telling us when an exception\u001b[39;00m\n\u001b[0;32m     77\u001b[0m         \u001b[39m# occurs in an exception handler.\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:143\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inc_overflow():\n\u001b[0;32m    142\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection()\n\u001b[0;32m    144\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m         \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:266\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    264\u001b[0m     \u001b[39m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mreturn\u001b[39;00m _ConnectionRecord(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:381\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pool \u001b[39m=\u001b[39m pool\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m connect:\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__connect()\n\u001b[0;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize_callback \u001b[39m=\u001b[39m deque()\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:677\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfresh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 677\u001b[0m     \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39msafe_reraise():\n\u001b[0;32m    678\u001b[0m         pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mError on connect(): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m    679\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    680\u001b[0m     \u001b[39m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[39m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# remove potential circular references\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_only:\n\u001b[1;32m---> 70\u001b[0m         compat\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m     71\u001b[0m             exc_value,\n\u001b[0;32m     72\u001b[0m             with_traceback\u001b[39m=\u001b[39;49mexc_tb,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m compat\u001b[39m.\u001b[39mpy3k \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info[\u001b[39m1\u001b[39m]:\n\u001b[0;32m     76\u001b[0m         \u001b[39m# emulate Py3K's behavior of telling us when an exception\u001b[39;00m\n\u001b[0;32m     77\u001b[0m         \u001b[39m# occurs in an exception handler.\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\pool\\base.py:673\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 673\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi_connection \u001b[39m=\u001b[39m connection \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49m_invoke_creator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    674\u001b[0m     pool\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreated new connection \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, connection)\n\u001b[0;32m    675\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfresh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\create.py:578\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    577\u001b[0m             \u001b[39mreturn\u001b[39;00m connection\n\u001b[1;32m--> 578\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\sqlalchemy\\engine\\default.py:598\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams):\n\u001b[0;32m    597\u001b[0m     \u001b[39m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbapi\u001b[39m.\u001b[39mconnect(\u001b[39m*\u001b[39mcargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcparams)\n",
      "File \u001b[1;32mp:\\Python\\GitHub\\insiders_clustering\\venv_10\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39masync_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[39m=\u001b[39m _ext\u001b[39m.\u001b[39mmake_dsn(dsn, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[39m=\u001b[39m _connect(dsn, connection_factory\u001b[39m=\u001b[39mconnection_factory, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m cursor_factory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[39m.\u001b[39mcursor_factory \u001b[39m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: (psycopg2.OperationalError) could not translate host name \"dbfinal.cegm6m2znhnj.sa-east-1.rds.amazonaws.com\" to address: Unknown host\n\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "endpoint = f\"postgresql://dbfinal:dbfinal2@dbfinal.cegm6m2znhnj.sa-east-1.rds.amazonaws.com/postgres\"\n",
    "\n",
    "conn = create_engine( endpoint)\n",
    "\n",
    "\n",
    " #create table\n",
    "query_create_table_insiders = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS insiders ( \n",
    "       grossrevenue   REAL,\n",
    "       gross_returns    REAL,\n",
    "       recencydays    REAL,   \n",
    "       qtd_items   REAL,\n",
    "       qtd_items_return     REAL,\n",
    "       avg_ticket   REAL,\n",
    "       frequency       REAL,\n",
    "       avg_basket_size  REAL,\n",
    "       n_purchases_unique   REAL,\n",
    "       cluster         INTEGER\n",
    "   )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "conn.execute( query_create_table_insiders )\n",
    "#conn.commit()\n",
    "#conn.close()\n",
    "\n",
    "# insert data\n",
    "df9.to_sql( 'insiders', con=conn, if_exists='replace', index=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>gross_returns</th>\n",
       "      <th>recencydays</th>\n",
       "      <th>qtd_items</th>\n",
       "      <th>qtd_items_return</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>n_purchases_unique</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.043062</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.066986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gross_revenue  gross_returns  recencydays  qtd_items  \\\n",
       "0       17850            3.0            2.0            0          0   \n",
       "1       13047            2.0            2.0            0          1   \n",
       "2       12583            3.0            2.0            0          3   \n",
       "3       13748            1.0            0.0            0          1   \n",
       "4       15100            1.0            2.0            0          0   \n",
       "\n",
       "   qtd_items_return  avg_ticket  frequency  avg_basket_size  \\\n",
       "0                 2    0.028434   1.000000         0.003532   \n",
       "1                 1    0.001893   0.001395         0.009761   \n",
       "2                 2    0.000350   0.002052         0.023773   \n",
       "3                 0    0.000410   0.000734         0.006135   \n",
       "4                 2    0.002484   0.003985         0.001814   \n",
       "\n",
       "   n_purchases_unique  cluster  \n",
       "0            0.157895        4  \n",
       "1            0.043062        4  \n",
       "2            0.066986        2  \n",
       "3            0.019139        0  \n",
       "4            0.009569        4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get query\n",
    "\n",
    "query_collect = \"\"\"\n",
    "SELECT * FROM insiders\n",
    "\"\"\"\n",
    "\n",
    "df=pd.read_sql_query( query_collect, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.clear_compiled_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rodou tudo\n"
     ]
    }
   ],
   "source": [
    "print('rodou tudo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('automl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "25221b6b9a4d399886f2cc4863e60b0fd11067ce172b33ecf50faf510e9d19c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
